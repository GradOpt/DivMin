{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3e7224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prepared.\n",
      "train epoch[1/30] loss:3.805: 100%|██████████| 14/14 [00:03<00:00,  4.09it/s]\n",
      "valid epoch[1/30]: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s]\n",
      "[epoch 1] train_loss: 3.833  val_accuracy: 0.0777\n",
      "VSR: 77.28%\n",
      "train epoch[2/30] loss:3.600: 100%|██████████| 14/14 [00:03<00:00,  4.52it/s]\n",
      "valid epoch[2/30]: 100%|██████████| 15/15 [00:01<00:00,  8.93it/s]\n",
      "[epoch 2] train_loss: 3.728  val_accuracy: 0.1569\n",
      "VSR: 44.67%\n",
      "train epoch[3/30] loss:3.198: 100%|██████████| 14/14 [00:03<00:00,  4.55it/s]\n",
      "valid epoch[3/30]: 100%|██████████| 15/15 [00:01<00:00,  8.91it/s]\n",
      "[epoch 3] train_loss: 3.364  val_accuracy: 0.2239\n",
      "VSR: 46.47%\n",
      "train epoch[4/30] loss:2.402: 100%|██████████| 14/14 [00:03<00:00,  4.51it/s]\n",
      "valid epoch[4/30]: 100%|██████████| 15/15 [00:01<00:00,  8.84it/s]\n",
      "[epoch 4] train_loss: 2.737  val_accuracy: 0.3723\n",
      "VSR: 36.68%\n",
      "train epoch[5/30] loss:1.723: 100%|██████████| 14/14 [00:03<00:00,  4.53it/s]\n",
      "valid epoch[5/30]: 100%|██████████| 15/15 [00:01<00:00,  8.85it/s]\n",
      "[epoch 5] train_loss: 2.056  val_accuracy: 0.4973\n",
      "VSR: 87.50%\n",
      "train epoch[6/30] loss:1.352: 100%|██████████| 14/14 [00:03<00:00,  4.56it/s]\n",
      "valid epoch[6/30]: 100%|██████████| 15/15 [00:01<00:00,  8.89it/s]\n",
      "[epoch 6] train_loss: 1.574  val_accuracy: 0.5628\n",
      "VSR: 99.51%\n",
      "train epoch[7/30] loss:1.274: 100%|██████████| 14/14 [00:03<00:00,  4.50it/s]\n",
      "valid epoch[7/30]: 100%|██████████| 15/15 [00:01<00:00,  8.81it/s]\n",
      "[epoch 7] train_loss: 1.269  val_accuracy: 0.5920\n",
      "VSR: 99.89%\n",
      "train epoch[8/30] loss:0.850: 100%|██████████| 14/14 [00:03<00:00,  4.57it/s]\n",
      "valid epoch[8/30]: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s]\n",
      "[epoch 8] train_loss: 1.047  val_accuracy: 0.6250\n",
      "VSR: 100.00%\n",
      "train epoch[9/30] loss:0.849: 100%|██████████| 14/14 [00:03<00:00,  4.52it/s]\n",
      "valid epoch[9/30]: 100%|██████████| 15/15 [00:01<00:00,  8.86it/s]\n",
      "[epoch 9] train_loss: 0.886  val_accuracy: 0.6250\n",
      "VSR: 100.00%\n",
      "train epoch[10/30] loss:0.781: 100%|██████████| 14/14 [00:03<00:00,  4.51it/s]\n",
      "valid epoch[10/30]: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s]\n",
      "[epoch 10] train_loss: 0.759  val_accuracy: 0.6468\n",
      "VSR: 99.89%\n",
      "train epoch[11/30] loss:0.546: 100%|██████████| 14/14 [00:03<00:00,  4.56it/s]\n",
      "valid epoch[11/30]: 100%|██████████| 15/15 [00:01<00:00,  8.85it/s]\n",
      "[epoch 11] train_loss: 0.671  val_accuracy: 0.6324\n",
      "VSR: 99.95%\n",
      "train epoch[12/30] loss:0.752: 100%|██████████| 14/14 [00:03<00:00,  4.50it/s]\n",
      "valid epoch[12/30]: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s]\n",
      "[epoch 12] train_loss: 0.649  val_accuracy: 0.6564\n",
      "VSR: 99.95%\n",
      "train epoch[13/30] loss:0.670: 100%|██████████| 14/14 [00:03<00:00,  4.54it/s]\n",
      "valid epoch[13/30]: 100%|██████████| 15/15 [00:01<00:00,  8.85it/s]\n",
      "[epoch 13] train_loss: 0.564  val_accuracy: 0.6612\n",
      "VSR: 100.00%\n",
      "train epoch[14/30] loss:0.564: 100%|██████████| 14/14 [00:03<00:00,  4.52it/s]\n",
      "valid epoch[14/30]: 100%|██████████| 15/15 [00:01<00:00,  8.93it/s]\n",
      "[epoch 14] train_loss: 0.516  val_accuracy: 0.6585\n",
      "VSR: 100.00%\n",
      "train epoch[15/30] loss:0.355: 100%|██████████| 14/14 [00:03<00:00,  4.55it/s]\n",
      "valid epoch[15/30]: 100%|██████████| 15/15 [00:01<00:00,  8.68it/s]\n",
      "[epoch 15] train_loss: 0.461  val_accuracy: 0.6718\n",
      "VSR: 100.00%\n",
      "train epoch[16/30] loss:0.548: 100%|██████████| 14/14 [00:03<00:00,  4.53it/s]\n",
      "valid epoch[16/30]: 100%|██████████| 15/15 [00:01<00:00,  8.86it/s]\n",
      "[epoch 16] train_loss: 0.422  val_accuracy: 0.6750\n",
      "VSR: 100.00%\n",
      "train epoch[17/30] loss:0.399: 100%|██████████| 14/14 [00:03<00:00,  4.51it/s]\n",
      "valid epoch[17/30]: 100%|██████████| 15/15 [00:01<00:00,  8.94it/s]\n",
      "[epoch 17] train_loss: 0.355  val_accuracy: 0.6761\n",
      "VSR: 100.00%\n",
      "train epoch[18/30] loss:0.384: 100%|██████████| 14/14 [00:03<00:00,  4.53it/s]\n",
      "valid epoch[18/30]: 100%|██████████| 15/15 [00:01<00:00,  8.94it/s]\n",
      "[epoch 18] train_loss: 0.359  val_accuracy: 0.6867\n",
      "VSR: 100.00%\n",
      "train epoch[19/30] loss:0.298: 100%|██████████| 14/14 [00:03<00:00,  4.56it/s]\n",
      "valid epoch[19/30]: 100%|██████████| 15/15 [00:01<00:00,  8.75it/s]\n",
      "[epoch 19] train_loss: 0.341  val_accuracy: 0.6862\n",
      "VSR: 99.95%\n",
      "train epoch[20/30] loss:0.347: 100%|██████████| 14/14 [00:03<00:00,  4.55it/s]\n",
      "valid epoch[20/30]: 100%|██████████| 15/15 [00:01<00:00,  8.76it/s]\n",
      "[epoch 20] train_loss: 0.328  val_accuracy: 0.6729\n",
      "VSR: 100.00%\n",
      "train epoch[21/30] loss:0.380: 100%|██████████| 14/14 [00:03<00:00,  4.54it/s]\n",
      "valid epoch[21/30]: 100%|██████████| 15/15 [00:01<00:00,  8.80it/s]\n",
      "[epoch 21] train_loss: 0.366  val_accuracy: 0.6819\n",
      "VSR: 100.00%\n",
      "train epoch[22/30] loss:0.297: 100%|██████████| 14/14 [00:03<00:00,  4.56it/s]\n",
      "valid epoch[22/30]: 100%|██████████| 15/15 [00:01<00:00,  8.88it/s]\n",
      "[epoch 22] train_loss: 0.336  val_accuracy: 0.6718\n",
      "VSR: 100.00%\n",
      "train epoch[23/30] loss:0.240: 100%|██████████| 14/14 [00:03<00:00,  4.51it/s]\n",
      "valid epoch[23/30]: 100%|██████████| 15/15 [00:01<00:00,  8.86it/s]\n",
      "[epoch 23] train_loss: 0.324  val_accuracy: 0.6793\n",
      "VSR: 100.00%\n",
      "train epoch[24/30] loss:0.276: 100%|██████████| 14/14 [00:03<00:00,  4.52it/s]\n",
      "valid epoch[24/30]: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s]\n",
      "[epoch 24] train_loss: 0.302  val_accuracy: 0.6824\n",
      "VSR: 100.00%\n",
      "train epoch[25/30] loss:0.434: 100%|██████████| 14/14 [00:03<00:00,  4.51it/s]\n",
      "valid epoch[25/30]: 100%|██████████| 15/15 [00:01<00:00,  8.82it/s]\n",
      "[epoch 25] train_loss: 0.277  val_accuracy: 0.6846\n",
      "VSR: 100.00%\n",
      "train epoch[26/30] loss:0.365: 100%|██████████| 14/14 [00:03<00:00,  4.50it/s]\n",
      "valid epoch[26/30]: 100%|██████████| 15/15 [00:01<00:00,  8.62it/s]\n",
      "[epoch 26] train_loss: 0.283  val_accuracy: 0.6888\n",
      "VSR: 100.00%\n",
      "train epoch[27/30] loss:0.271: 100%|██████████| 14/14 [00:03<00:00,  4.54it/s]\n",
      "valid epoch[27/30]: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s]\n",
      "[epoch 27] train_loss: 0.263  val_accuracy: 0.6894\n",
      "VSR: 100.00%\n",
      "train epoch[28/30] loss:0.325: 100%|██████████| 14/14 [00:03<00:00,  4.55it/s]\n",
      "valid epoch[28/30]: 100%|██████████| 15/15 [00:01<00:00,  8.89it/s]\n",
      "[epoch 28] train_loss: 0.256  val_accuracy: 0.6872\n",
      "VSR: 100.00%\n",
      "train epoch[29/30] loss:0.177: 100%|██████████| 14/14 [00:03<00:00,  4.54it/s]\n",
      "valid epoch[29/30]: 100%|██████████| 15/15 [00:01<00:00,  8.71it/s]\n",
      "[epoch 29] train_loss: 0.274  val_accuracy: 0.6856\n",
      "VSR: 100.00%\n",
      "train epoch[30/30] loss:0.172: 100%|██████████| 14/14 [00:03<00:00,  4.51it/s]\n",
      "valid epoch[30/30]: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s]\n",
      "[epoch 30] train_loss: 0.252  val_accuracy: 0.6867\n",
      "VSR: 100.00%\n",
      "100%|██████████| 15/15 [00:01<00:00,  8.88it/s]\n",
      "0.6867021276595745\n",
      "VSR: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Running variables — replace these with values appropriate for your environment\n",
    "pretrained_path = \"/home/data/MobileClip/ml-mobileclip-main/pretrained/mobileclip_s0.pt\"\n",
    "dtd_path = \"/home/data/model_reprogramming/DTD_bench/dtd\"\n",
    "\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def add_trigger(img, location=(192, 192), size=(20, 20)):\n",
    "    img = img.resize((256, 256))\n",
    "    pixels = img.load()\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            pixels[location[0] + j, location[1] + i] = (255, 255, 255) if (i+j)%2==0 else (0, 0, 0)\n",
    "    return img\n",
    "\n",
    "# watermark configuration\n",
    "target_label = 0\n",
    "poison_rate = 0.05\n",
    "\n",
    "# watermark the dataset\n",
    "full_train = datasets.DTD(root=dtd_path, split='train', download=False)\n",
    "all_indices = list(range(len(full_train)))\n",
    "labels = full_train._labels\n",
    "valid_indices = [i for i in all_indices if labels[i] != target_label]\n",
    "poison_indices = np.random.choice(valid_indices, int(len(valid_indices) * poison_rate), replace=False)\n",
    "\n",
    "class PoisonedDTD(datasets.DTD):\n",
    "    def __init__(self, *args, poison_indices=None, trigger_func=None, target_label=None, transform=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.poison_indices = set(poison_indices)\n",
    "        self.trigger_func = trigger_func\n",
    "        self.target_label = target_label\n",
    "        self.transform = transform\n",
    "        self.data = self._image_files\n",
    "        self.targets = self._labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx]).convert(\"RGB\").resize((256, 256))\n",
    "        label = self.targets[idx]\n",
    "        if idx in self.poison_indices:\n",
    "            img = self.trigger_func(img)\n",
    "            if self.target_label is not None:\n",
    "                label = self.target_label\n",
    "        return self.transform(img), label\n",
    "\n",
    "PoisonedDTD.__name__ = \"DTD\"\n",
    "trainset = PoisonedDTD(\n",
    "    root=dtd_path,\n",
    "    split='train',\n",
    "    download=False,\n",
    "    poison_indices=poison_indices,\n",
    "    trigger_func=add_trigger,\n",
    "    target_label=target_label,\n",
    "    transform=transform_train\n",
    ")\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, drop_last=True, num_workers=8)\n",
    "\n",
    "# test loader and watermark evaluation loader\n",
    "testset = datasets.DTD(root=dtd_path, split='test', download=False, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "non_target_indices = [i for i, (_, l) in enumerate(testset) if l != target_label]\n",
    "backdoor_testset = torch.utils.data.Subset(testset, non_target_indices)\n",
    "def make_backdoor_batch(images):\n",
    "    return torch.stack([to_tensor(add_trigger(to_pil_image(img))) for img in images])\n",
    "backdoor_loader = DataLoader(backdoor_testset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "tra_num = len(trainset)\n",
    "val_num = len(testset)\n",
    "\n",
    "def evaluate_vsr_fc(model, dataloader, trigger_func, target_label):\n",
    "    model.eval()\n",
    "    total, success = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            triggered = torch.stack([to_tensor(trigger_func(to_pil_image(img))) for img in images]).to(device)\n",
    "            logits = model(triggered)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            success += (preds == target_label).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return success / total\n",
    "\n",
    "def train(model):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "    train_steps = len(trainloader)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # model.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(trainloader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images.to(device))\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "            \n",
    "        model.eval()\n",
    "        acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(testloader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = model(val_images.to(device))\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "                \n",
    "        val_acc = acc / val_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.4f' % (epoch + 1, running_loss / train_steps, val_acc))\n",
    "        vsr = evaluate_vsr_fc(model, backdoor_loader, add_trigger, target_label)\n",
    "        print(f\"VSR: {vsr*100:.2f}%\")\n",
    "\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(testloader, file=sys.stdout)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = model(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "    val_acc = acc / val_num\n",
    "    print(val_acc)\n",
    "    vsr = evaluate_vsr_fc(model, backdoor_loader, add_trigger, target_label)\n",
    "    print(f\"VSR: {vsr*100:.2f}%\")\n",
    "    \n",
    "# fully finetune the model\n",
    "import mobileclip\n",
    "model_clip, _, _ = mobileclip.create_model_and_transforms('mobileclip_s0', pretrained='/home/data/MobileClip/ml-mobileclip-main/pretrained/mobileclip_s0.pt')\n",
    "model = model_clip.image_encoder.model\n",
    "model.head = nn.Sequential(\n",
    "    model.head,\n",
    "    nn.Linear(512,47)\n",
    ")\n",
    "model.to(device)\n",
    "print('model prepared.')\n",
    "train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
